{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Faza 2:\n",
    "# Implementacija flair NER\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# from nltk import pos_tag, word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('gutenberg')\n",
    "# import re\n",
    "# import string\n",
    "# from itertools import combinations\n",
    "# from collections import Counter\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-19 10:46:01,741 loading file /Users/matijagercer/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
      "2022-05-19 10:46:06,352 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# Use flair named entity recognition\n",
    "tagger = SequenceTagger.load('ner')     # ner, ner-ontonotes, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        text = text.replace('\\r', ' ').replace('\\n', ' ')\\\n",
    "            .replace(\"’\", \"'\").replace(\"\\\"\", \"\").replace(\"”\", \"\").replace(\"“\", \"\")\n",
    "    return text\n",
    "\n",
    "def flair_NER(book):\n",
    "    \"\"\"\n",
    "    flair_NER vrne seznam, v katerem so shranjene prepoznane identitete glede na posamezni stavek\n",
    "    :param book: str\n",
    "    :return: entity_dict (seznam slovarjev kot npr. [name, tag, start_pos, stop_pos, line_num. token_num])\n",
    "    \"\"\"\n",
    "\n",
    "    # 00 Pretvori knjigo v stavke:\n",
    "    sent = sent_tokenize(book)\n",
    "\n",
    "    # 01 NER model\n",
    "    entity_dict = []\n",
    "    for line_num, line in enumerate(tqdm(sent)):\n",
    "\n",
    "        # 01a Predict:\n",
    "        sentence = Sentence(line)\n",
    "        tagger.predict(sentence)\n",
    "\n",
    "        # 01b Vmesni izpis (brez lokacije):\n",
    "        #print(sentence.to_tagged_string())\n",
    "        #print(sentence.get_spans('ner'))\n",
    "\n",
    "        # 01c Ekstrakcija podatka iz stavka:\n",
    "        for entity in sentence.get_spans('ner'):        # veliko različnih flair - nerov\n",
    "            name = entity.text\n",
    "\n",
    "            # str location\n",
    "            # start_pos = entity.start_position    # št. str\n",
    "            # stop_pos = entity.end_position      # št. str\n",
    "\n",
    "            # token location\n",
    "            tmp_flag = True\n",
    "            for token in entity:\n",
    "                if tmp_flag:\n",
    "                    start_pos = token.idx -1\n",
    "                    stop_pos = token.idx\n",
    "                else:\n",
    "                    stop_pos = token.idx\n",
    "                tmp_flag = False\n",
    "\n",
    "            tag = entity.get_label(\"ner\").value             # tag = entity.tag\n",
    "            conf_score = entity.get_label(\"ner\").score      # conf_score = entity.score\n",
    "\n",
    "            info_dict = {}\n",
    "            info_dict[\"name\"] = name\n",
    "            info_dict[\"tag\"] = tag\n",
    "            info_dict[\"start_pos\"] = start_pos\n",
    "            info_dict[\"stop_pos\"] = stop_pos\n",
    "            info_dict[\"line_num\"] = line_num\n",
    "\n",
    "            entity_dict.append(info_dict)\n",
    "\n",
    "    return entity_dict\n",
    "\n",
    "def get_names_from_NER(entity_dict):\n",
    "    \"\"\"\n",
    "    get_names_from_NER sprejme entity_dict in vrne urejen seznam terk (\"ime\", št_zaznano)\n",
    "    :param entity_dict: dict (seznam dictov)\n",
    "    :return: unique_names: list\n",
    "    \"\"\"\n",
    "    unique_names = {}\n",
    "\n",
    "    for entity in entity_dict:\n",
    "        if entity[\"tag\"] == \"PER\":\n",
    "            if entity[\"name\"] not in unique_names:\n",
    "                unique_names[entity[\"name\"]] = 1\n",
    "            else:\n",
    "                unique_names[entity[\"name\"]] += 1\n",
    "    unique_names = sorted(unique_names.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "    return unique_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "book = read_text('../data/books/ASongOfIceAndFire/AGOT/chapters/Bran_1_1.txt')\n",
    "entity_dict = flair_NER(book)\n",
    "unique_names = get_names_from_NER(entity_dict)\n",
    "\n",
    "for (name, num) in unique_names:\n",
    "    if True: #num > 1:\n",
    "        print(name, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_entities(sentences):\n",
    "    threshold = 0.0001\n",
    "    named_entities = []\n",
    "    named_entities_thresholded = []\n",
    "    for s in sentences:\n",
    "        named_entities += NER(s)\n",
    "\n",
    "    named_entities = [ne for ne in named_entities if ne not in common_english_words]\n",
    "    named_entities = Counter(named_entities)\n",
    "    for ne in named_entities:\n",
    "        if named_entities[ne] >= threshold * len(sentences):\n",
    "            named_entities_thresholded.append(ne)\n",
    "\n",
    "    return named_entities_thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_characters(book, characters, number_of_characters):\n",
    "    cv = CountVectorizer(vocabulary=characters, stop_words='english')\n",
    "    freq = cv.fit_transform([book.lower()])\n",
    "    freq = pd.DataFrame(freq.toarray(), columns=cv.get_feature_names())\n",
    "    freq = freq.T\n",
    "    freq = freq.sort_values(by=0, ascending=False)\n",
    "    freq = freq[0:number_of_characters]\n",
    "\n",
    "    characters = list(freq.index)\n",
    "    return freq, characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_graph(name_list, name_frequency, matrix, plt_name, mode, path=''):\n",
    "\n",
    "    label = {i: i for i in name_list}\n",
    "    edge_list = []\n",
    "    shape = matrix.shape[0]\n",
    "    triangle = list(zip(*np.where(np.triu(np.ones([shape, shape])) == 0)))\n",
    "    normalized_matrix = matrix / np.max(np.abs(matrix))\n",
    "    normalized_frequency = np.array(name_frequency) / np.max(name_frequency)\n",
    "    weight = np.log(np.abs(1000 * normalized_matrix) + 1) * 0.7\n",
    "    color = 2000 * normalized_matrix\n",
    "    for i in triangle:\n",
    "        edge_list.append((name_list[i[0]], name_list[i[1]], {'weight': weight[i], 'color': color[i]}))\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(name_list)\n",
    "    G.add_edges_from(edge_list)\n",
    "    edges = G.edges()\n",
    "    weights = [G[u][v]['weight'] for u, v in edges]\n",
    "    colors = [G[u][v]['color'] for u, v in edges]\n",
    "\n",
    "    \n",
    "    nx.draw_random(G, node_color='#A0CBE2', node_size=normalized_frequency * 2000,\n",
    "            linewidths=10, labels=label, edge_color=colors, with_labels=True,\n",
    "            width=weights, edge_vmin=-1000, edge_vmax=1000)\n",
    "\n",
    "\n",
    "    plt.savefig(path + plt_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "common_english_words = get_common_english_words('../data/common_english_words.txt')\n",
    "book = read_text('../data/books/ASongOfIceAndFire/GoT1_long.txt')\n",
    "sentences = nltk.sent_tokenize(book)\n",
    "characters = get_named_entities(sentences)\n",
    "freq, main_characters = get_main_characters(book, characters, number_of_characters=25)\n",
    "sentiment_mtx, _ = get_mtx(sentences, main_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = freq.values\n",
    "temp = temp.tolist()\n",
    "freq = [item for sublist in temp for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(main_characters, freq, sentiment_mtx, \"test\" + ' sentiment graph', 'sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}