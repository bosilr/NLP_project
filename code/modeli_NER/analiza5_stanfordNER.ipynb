{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import operator\n",
    "from sner import Ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model = \"/Users/matijagercer/Desktop/stanford-ner-2020-11-17/classifiers/english.all.3class.distsim.crf.ser.gz\"\n",
    "jar = \"/Users/matijagercer/Desktop/stanford-ner-2020-11-17/stanford-ner-4.2.0.jar\"\n",
    "st = StanfordNERTagger(model, jar,encoding='utf-8')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Termina:\n",
    "# cd your_stanford_ner_dir\n",
    "# java -Djava.ext.dirs=./lib -cp stanford-ner.jar edu.stanford.nlp.ie.NERServer -port 9199 -loadClassifier ./classifiers/english.all.3class.distsim.crf.ser.gz\n",
    "\n",
    "# Za več preberi:\n",
    "# https://stackoverflow.com/questions/33748554/how-to-speed-up-ne-recognition-with-stanford-ner-with-python-nltk\n",
    "\n",
    "tagger = Ner(host='localhost',port=9199)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        text = text.replace('\\r', ' ').replace('\\n', ' ')\\\n",
    "            .replace(\"’\", \"'\").replace(\"\\\"\", \"\").replace(\"”\", \"\").replace(\"“\", \"\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def stanford_NER(book):\n",
    "    \"\"\"\n",
    "    stanford_NER vrne seznam, v katerem so shranjene prepoznane identitete glede na posamezni stavek\n",
    "    :param book: str\n",
    "    :return: entity_dict (seznam slovarjev kot npr. [name, tag, start_pos, stop_pos, line_num. token_num])\n",
    "    \"\"\"\n",
    "\n",
    "    # 00 Pretvori knjigo v stavke:\n",
    "    sentences = sent_tokenize(book)\n",
    "    entity_dict = []\n",
    "\n",
    "    for line_num, line in enumerate(sentences):\n",
    "\n",
    "        #tokenized_text = word_tokenize(line)\n",
    "        #classified_text = st.tag(tokenized_text)\n",
    "\n",
    "        classified_text = tagger.get_entities(line)\n",
    "\n",
    "        token_num = 0\n",
    "        for (name, tag) in classified_text:\n",
    "            if tag != 'O':\n",
    "                info_dict = {}\n",
    "                info_dict[\"name\"] = name\n",
    "                info_dict[\"tag\"] = tag\n",
    "                info_dict[\"start_pos\"] = token_num\n",
    "                info_dict[\"stop_pos\"] = token_num+1\n",
    "                info_dict[\"line_num\"] = line_num\n",
    "                entity_dict.append(info_dict)\n",
    "            token_num += 1\n",
    "\n",
    "    return entity_dict\n",
    "\n",
    "\n",
    "def get_names_from_NER(entity_dict):\n",
    "    \"\"\"\n",
    "    get_names_from_NER sprejme entity_dict in vrne urejen seznam terk (\"ime\", št_zaznano)\n",
    "    :param entity_dict: dict (seznam dictov)\n",
    "    :return: unique_names: list\n",
    "    \"\"\"\n",
    "    unique_names = {}\n",
    "\n",
    "    for entity in entity_dict:\n",
    "        if entity[\"tag\"] == \"PERSON\":\n",
    "            if entity[\"name\"] not in unique_names:\n",
    "                unique_names[entity[\"name\"]] = 1\n",
    "            else:\n",
    "                unique_names[entity[\"name\"]] += 1\n",
    "    unique_names = sorted(unique_names.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "    return unique_names\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jon 31\n",
      "Robb 29\n",
      "Greyjoy 12\n",
      "Jory 11\n",
      "Theon 7\n",
      "Bran 6\n",
      "Hullen 5\n",
      "Stark 3\n",
      "Snow 3\n",
      "Nan 2\n",
      "Starks 2\n",
      "Cassel 2\n",
      "Robert 2\n",
      "of 2\n",
      "the 2\n",
      "Mance 1\n",
      "Rayder 1\n",
      "Eddard 1\n",
      "House 1\n",
      "Baratheon 1\n",
      "Warden 1\n",
      "North 1\n",
      "Targaryen 1\n",
      "Harwin 1\n",
      "Ser 1\n",
      "Rodrik 1\n",
      "Rickon 1\n",
      "Desmond 1\n",
      "Winterfell 1\n"
     ]
    }
   ],
   "source": [
    "book = read_text('../../data/books/ASongOfIceAndFire/AGOT/chapters/Bran_1_1.txt')\n",
    "entity_dict = stanford_NER(book)\n",
    "unique_names = get_names_from_NER(entity_dict)\n",
    "\n",
    "for (name, num) in unique_names:\n",
    "    if True: #num > 1:\n",
    "        print(name, num)\n",
    "\n",
    "print(entity_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}