{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.0.json:   0%|   …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efdac11a18204d2a8c3460024596b990"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 16:40:22 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-05-19 16:40:22 INFO: Use device: cpu\n",
      "2022-05-19 16:40:22 INFO: Loading: tokenize\n",
      "2022-05-19 16:40:22 INFO: Loading: ner\n",
      "2022-05-19 16:40:23 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        text = text.replace('\\r', ' ').replace('\\n', ' ')\\\n",
    "            .replace(\"’\", \"'\").replace(\"\\\"\", \"\").replace(\"”\", \"\").replace(\"“\", \"\")\n",
    "    return text\n",
    "\n",
    "def stanza_NER(book):\n",
    "    \"\"\"\n",
    "    stanza_NER vrne seznam, v katerem so shranjene prepoznane identitete glede na posamezni stavek\n",
    "    :param book: str\n",
    "    :return: entity_dict (seznam slovarjev kot npr. [name, tag, start_pos, stop_pos, line_num. token_num])\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp(book)\n",
    "    entity_dict = []\n",
    "\n",
    "\n",
    "    for line_num, sent in enumerate(doc.sentences):\n",
    "        token_num = 0\n",
    "        for token in sent.tokens:\n",
    "            # S - samostojna\n",
    "            # B - na zacetku\n",
    "            # I - vmes\n",
    "            # E - na koncu\n",
    "            if token.ner == \"S-PERSON\" or token.ner == \"B-PERSON\" or token.ner == \"E-PERSON\" or token.ner == \"I-PERSON\":\n",
    "                info_dict = {}\n",
    "                info_dict[\"name\"] = token.text\n",
    "                info_dict[\"tag\"] = token.ner\n",
    "                info_dict[\"start_pos\"] = token_num\n",
    "                info_dict[\"stop_pos\"] = token_num +1\n",
    "                info_dict[\"line_num\"] = line_num\n",
    "                entity_dict.append(info_dict)\n",
    "                token_num += 1\n",
    "\n",
    "    return entity_dict\n",
    "\n",
    "\n",
    "def get_names_from_NER(entity_dict):\n",
    "    \"\"\"\n",
    "    get_names_from_NER sprejme entity_dict in vrne urejen seznam terk (\"ime\", št_zaznano)\n",
    "    :param entity_dict: dict (seznam dictov)\n",
    "    :return: unique_names: list\n",
    "    \"\"\"\n",
    "    unique_names = {}\n",
    "\n",
    "    for entity in entity_dict:\n",
    "        if entity[\"tag\"] == \"S-PERSON\" or entity[\"tag\"] == \"N-PERSON\":\n",
    "            if entity[\"name\"] not in unique_names:\n",
    "                unique_names[entity[\"name\"]] = 1\n",
    "            else:\n",
    "                unique_names[entity[\"name\"]] += 1\n",
    "    unique_names = sorted(unique_names.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "    return unique_names\n",
    "\n",
    "def merge_person_names(entity_dict):\n",
    "     \"\"\"\n",
    "    merge_person_names sprejme vse označene persone (S,B,I,E - PERSON) in smiselno zloži imena. Vrne (S - Person) če je\n",
    "    nespremenjeno in N - Person če je bila združitev... \n",
    "    :param entity_dict: dict (seznam dictov)\n",
    "    :return: entity_dict_clean: list\n",
    "    \"\"\"\n",
    "    entity_dict_clean = []\n",
    "\n",
    "    for entity_num, entity in enumerate(entity_dict):\n",
    "\n",
    "        if entity[\"tag\"] == \"S-PERSON\":\n",
    "            entity_dict_clean.append(entity)\n",
    "\n",
    "        elif entity[\"tag\"] == \"B-PERSON\":\n",
    "            tmp_entity = entity.copy()\n",
    "            try:\n",
    "                for i in range(10):\n",
    "                    next_entity = entity_dict[entity_num + i]\n",
    "                    if next_entity[\"line_num\"] ==  tmp_entity[\"line_num\"] and (next_entity[\"tag\"] == \"I-PERSON\" or next_entity[\"tag\"] == \"E-PERSON\"):\n",
    "                        tmp_entity[\"name\"] = tmp_entity[\"name\"] + \" \" + next_entity[\"name\"]\n",
    "                        tmp_entity[\"tag\"] = \"N-PERSON\"\n",
    "                        tmp_entity[\"stop_pos\"] = next_entity[\"stop_pos\"]\n",
    "                        if next_entity[\"tag\"] == \"E-PERSON\":\n",
    "                            break\n",
    "            except:\n",
    "                pass\n",
    "            entity_dict_clean.append(tmp_entity)\n",
    "    return entity_dict_clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "book = read_text('../data/books/ASongOfIceAndFire/AGOT/chapters/Bran_1_1.txt')\n",
    "entity_dict = stanza_NER(book)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bran 46\n",
      "Robb 29\n",
      "Jon 29\n",
      "Jory 9\n",
      "Greyjoy 7\n",
      "Theon Greyjoy 6\n",
      "Hullen 5\n",
      "Stark 3\n",
      "Snow 3\n",
      "Winterfell 2\n",
      "Jory Cassel 2\n",
      "Jon Snow 2\n",
      "Mance Rayder 1\n",
      "Old Nan 1\n",
      "Eddard Stark 1\n",
      "Ice 1\n",
      "Robert of the House Baratheon 1\n",
      "King of the Andals 1\n",
      "Rhoynar 1\n",
      "Eddard 1\n",
      "Warden of the North 1\n",
      "Theon 1\n",
      "Nan 1\n",
      "Robert 1\n",
      "Starks 1\n",
      "Harwin 1\n",
      "Ser Rodrik 's 1\n",
      "Rickon 1\n",
      "no Stark 1\n",
      "Desmond 1\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "entity_dict_clean = merge_person_names(entity_dict)\n",
    "unique_names = get_names_from_NER(entity_dict_clean)\n",
    "\n",
    "sum_num = 0\n",
    "for (name, num) in unique_names:\n",
    "    if True: #num > 1:\n",
    "        print(name, num)\n",
    "        sum_num = sum_num + num\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}